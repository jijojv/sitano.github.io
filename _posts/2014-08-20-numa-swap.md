---
layout: post
title: Swap out problem on NUMA architecture
---

We hit a problem on our production servers. It looks like this:

![]({{ Site.url }}/public/memory-zonerm0.png)

Server has 3 _memcached_ instances installed for 3\*4GB = 12GB and
2 _redis_ instances installed for 4GB + async saves through out fork syscall
every 10-30 minutes + some other services installed. There are 48GB of memory in total.

It’s NUMA architecture, 2 cpus => 2 mem banks, 10/21 memory bank access,
default policy = local, all processes not pinned start at first mem socket.

Server is `Ubuntu 12.04.3 LTS` with kernel `Linux 3.2.0-24-generic #37-Ubuntu SMP x86\_64`

    vm.swappiness = 0
    vm.zone_reclaim_mode = 0
    default numa policy

Picture above tells the story. When memory heavy processes hit
24GB memory cap (this is amount of memory on each memory socket)
(case is N0 is exhausted, see `numactl -H`)
OS memory scheduler swaps out those memory even in a case, there is 24 gb
of free memory owned by the buffer cache on the secondary memory socket.

As can be seen, there is 22.61GB of cache right now. It filled with
nginx access logs (>10GB uncompressed -> 3GB rotated) which will be
rotated / compressed at 6 o’clock.

Interesting thing is, when swapping in all the memory with `swapoff -a && swapon -a`,
memory from the swap will be partially placed into another memory zone. (OOM
will occur if some process suddenly will start to reserve corresponding
amounts of memory blocks)

### Why is that happening?

Kernel have to redistribute memory from processes all allocated on the
first memory socket after all its memory have exhausted. There are 2
parameters affects this:

* zone reclaimation policy
* numa memory distribution policy

### Possible solution

Change memory distribution policy (i.e. interleave, zone\_reclaim\_mode = 1) or 
pin some process to allocate their memory on another socket.

### What we done

We pinned 3 _memcached_ processes to use _PREFERED_ memory policy and to start
memory allocation on second node. This will allocate 12GB of memory on the
second cpu.

    $ numactl -H

    available: 2 nodes (0-1)
    node 0 cpus: 0 1 2 3 8 9 10 11
    node 0 size: 24567 MB
    node 0 free: 2938 MB
    node 1 cpus: 4 5 6 7 12 13 14 15
    node 1 size: 24576 MB
    node 1 free: 11000 MB
    node distances:
    node   0   1
      0:  10  21
      1:  21  10

    $ numactl --cpunodebind=1 --preferred=1 -- memcached

### Documentation

Take a look at a description of
[vm.zone\_reclaim\_mode](https://www.kernel.org/doc/Documentation/sysctl/vm.txt)
parameter.

**zone\_reclaim\_mode**:

Zone\_reclaim\_mode allows someone to set more or less aggressive approaches to
reclaim memory when a zone runs out of memory. If it is set to zero then no
zone reclaim occurs. Allocations will be satisfied from other zones / nodes
in the system.

This is value ORed together of

    1   = Zone reclaim on
    2   = Zone reclaim writes dirty pages out
    4   = Zone reclaim swaps pages

zone\_reclaim\_mode is disabled by default.  For file servers or workloads
that benefit from having their data cached, zone\_reclaim\_mode should be
left disabled as the caching effect is likely to be more important than
data locality.

zone\_reclaim may be enabled if it’s known that the workload is partitioned
such that each partition fits within a NUMA node and that accessing remote
memory would cause a measurable performance reduction.  The page allocator
will then reclaim easily reusable pages (those page cache pages that are
currently not used) before allocating off node pages.

Allowing zone reclaim to write out pages stops processes that are
writing large amounts of data from dirtying pages on other nodes. Zone
reclaim will write out dirty pages if a zone fills up and so effectively
throttle the process. This may decrease the performance of a single process
since it cannot use all of system memory to buffer the outgoing writes
anymore but it preserve the memory on other nodes so that the performance
of other processes running on other nodes will not be affected.

Allowing regular swap effectively restricts allocations to the local
node unless explicitly overridden by memory policies or cpuset
configurations.

_So_, it may be beneficial to switch off zone reclaim if the system is
used for a file server and all of memory should be used for caching files
from disk. In that case the caching effect is more important than
data locality.

### To read

[PostgreSQL, NUMA and zone reclaim mode on linux](http://frosty-postgres.blogspot.ru/2012/08/postgresql-numa-and-zone-reclaim-mode.html)

[Optimizing Linux Memory Management for Low-latency / High-throughput Databases](http://engineering.linkedin.com/performance/optimizing-linux-memory-management-low-latency-high-throughput-databases)

[OOM relation to vm.swappiness=0 in new kernel](http://www.mysqlperformanceblog.com/2014/04/28/oom-relation-vm-swappiness0-new-kernel/)

[What is Linux Memory Policy?](https://www.kernel.org/doc/Documentation/vm/numa_memory_policy.txt)

In the Linux kernel, “memory policy” determines from which node the kernel will
allocate memory in a NUMA system or in an emulated NUMA system.

**System Default Policy**: this policy is “hard coded” into the kernel.  It
is the policy that governs all page allocations that aren’t controlled
by one of the more specific policy scopes discussed below.  When the
system is “up and running”, the system default policy will use **“local
allocation”** described below.  However, during boot up, the system
default policy will be set to **interleave** allocations across all nodes
with “sufficient” memory, so async not to overload the initial boot node
with boot-time allocations.
